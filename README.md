# ğŸ§  Deepfake Detection Using AI/ML
ğŸ‘©â€ğŸ’» Author: Sravya Kakarlapudi
# ğŸ¯ Objective

This project aims to detect deepfakes â€” highly realistic synthetic faces generated by models such as StyleGAN â€” using deep learning.
We apply computer vision and transfer learning techniques to classify facial images as real or fake.

Deepfakes pose major security and misinformation challenges in financial systems, media, and identity verification.
This project demonstrates how AI can help automatically identify synthetic visual content.

# ğŸ—‚ï¸ Dataset

Dataset: 140K Real and Fake Faces (from Kaggle)

Folder Structure
train/
    â”œâ”€â”€ real/
    â””â”€â”€ fake/
valid/
test/

Metadata CSVs

train.csv, valid.csv, test.csv
Each file includes:
| Column | Description |
|---------|--------------|
| image_id | Unique ID for image file |
| label | 1 = real, 0 = fake |
| path | File path to image |

# âš™ï¸ Step 1: Data Ingestion & Preprocessing

Since we use transfer learning, images must match the pretrained modelâ€™s expected input format.

Key preprocessing steps:

Load real and fake image files

Resize to 224Ã—224 pixels

Normalize pixel values to [0,1]

Label real as 0, fake as 1

Batch and prefetch datasets for GPU efficiency

The processed dataset contained 100,000 training images, 20,000 validation, and 20,000 test samples.

# ğŸ§© Step 2: Model Development â€“ Transfer Learning

We use MobileNetV2 pretrained on ImageNet, excluding its top layer, and fine-tune it for binary classification.

Architecture

Base model: MobileNetV2 (frozen initial layers)

Added layers:

GlobalAveragePooling2D()

Dense(128, activation='relu')

Dense(1, activation='sigmoid')

Loss: Binary Cross-Entropy

Optimizer: Adam

Metrics: Accuracy

Training was conducted for 10 epochs using mixed precision for speed.

# ğŸ“ˆ Model Performance
Metric	Value
Accuracy	0.7595
Precision	0.7539
Recall	0.7705
F1-score	0.7621
ROC-AUC	0.8399

# Confusion Matrix:

	Predicted Real	Predicted Fake
Actual Real	TN	FP
Actual Fake	FN	TP

âœ… The model achieves balanced precision and recall â€” it catches most fake images while keeping false positives low.

# ğŸ§  Did Transfer Learning Help?

Absolutely.
Using a pretrained MobileNetV2 drastically improved the modelâ€™s ability to detect subtle pixel-level inconsistencies.
Low-level features (edges, textures, lighting) from ImageNet gave the model a strong foundation, reducing both data and training time.

Without transfer learning, a CNN trained from scratch would likely underperform or fail to converge on this dataset.

# ğŸ” Step 3: Baseline Comparison â€” Metadata Model

To evaluate whether metadata alone can detect fakes, we trained a Logistic Regression model using only train.csv metadata.

Metric	Tabular Model	Transfer Learning
Accuracy	0.5000	0.7595
Precision	0.0000	0.7539
Recall	0.0000	0.7705
F1-score	0.0000	0.7621
ROC-AUC	0.5000	0.8399

âŒ The tabular model performed no better than random guessing.
âœ… The image-based deep learning model clearly outperformed it across all metrics.

# ğŸ’¬ Reflection

Even with transfer learning, accuracy plateaued around 76%, and ROC-AUC at 0.84 â€” highlighting how convincing modern deepfakes can be.
The model was slightly more sensitive than precise, showing it was better at detecting fakes than avoiding false positives.

This project reinforced that:

Deepfake detection is complex, requiring visual and contextual signals.

Metadata-only models are insufficient when visual manipulation is the primary fraud vector.

Hybrid systems that combine visual AI with metadata patterns (e.g., image origin, timestamp, upload source) can provide stronger real-world protection.

# ğŸ§® How Metadata Can Complement Deep Learning in Fraud Analytics

Metadata (file origin, creation time, device, etc.) can flag anomalous behavior even before analyzing images.

Combined models can cross-validate image authenticity against contextual information.

For cost-sensitive systems, metadata can serve as a first-line fraud filter, reducing the load on GPU-intensive image models.

# ğŸ§° Tech Stack

Python, TensorFlow / Keras, NumPy, Pandas

MobileNetV2 (Transfer Learning)

Matplotlib, Seaborn for visualization

Scikit-learn for metrics and baseline modeling
